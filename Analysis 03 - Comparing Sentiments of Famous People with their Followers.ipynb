{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 03: Comparing Sentiments of Famous People with their Followers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SETTING UP THE TWITTER API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "\n",
    "consumer_key = 'qWaI6kizU7SAcRNc6EnnoNChq'\n",
    "consumer_secret = 'xumE7NgIZMiLCUXFeEl0pr3zhsuqdLvOPB0tG94HBQ8PgP2vsK'\n",
    "access_token = '2747565082-8g1OYC9aFI4NxRInAV5ArxV1te4V6alDLHlQuNn'\n",
    "access_token_secret = 'rDMmFApw3H5vL5KqVRxwRKdmJCkRdmrqjG8CCfmVroNKV'\n",
    "\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PREPARING THE TRAINING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Source: https://colab.research.google.com/drive/1PHv-IRLPCtv7oTcIGbsgZHqrB5LPvB7S\n",
    "\n",
    "training_data = pd.read_csv(r\"C:/Users/Raheyma Arshad/Desktop/INFO 5731 Term Project/reviews.csv\")\n",
    "training_data = training_data[['content', 'score']]\n",
    "training_data.columns = ['Review', 'Sentiment']\n",
    "training_data = training_data.astype({\"Sentiment\": int})\n",
    "\n",
    "def sentiment(x):\n",
    "    if x in [1, 2]:\n",
    "        return 'Negative'\n",
    "    if x == 3:\n",
    "        return 'Neutral'\n",
    "    if x in [4, 5]:\n",
    "        return 'Positive'\n",
    "\n",
    "training_data['Sentiment'] = training_data['Sentiment'].apply(lambda x: sentiment(x))\n",
    "\n",
    "# Cleaning and Data Preprocessing\n",
    "\n",
    "import re \n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "stop = stopwords.words('english')\n",
    "from textblob import Word\n",
    "\n",
    "training_data['Clean Review'] = training_data['Review'].apply(lambda x: re.sub('https?:\\/\\/(www\\.)?[-a-zA-Z0–9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0–9@:%_\\+.~#?&//=]*)', '', x))\n",
    "training_data['Clean Review'] = training_data['Clean Review'].apply(lambda x: re.sub('[-a-zA-Z0–9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0–9@:%_\\+.~#?&//=]*)', '', x))\n",
    "training_data['Clean Review'] = training_data['Clean Review'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "training_data['Clean Review'] = training_data['Clean Review'].str.replace('[^\\w\\s]','')\n",
    "training_data['Clean Review'] = training_data['Clean Review'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "training_data['Clean Review'] = training_data['Clean Review'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TRAINING THE TFIDF-BASED SUPPORT VECTOR MACHINE (SVM) MODEL ON THE TRAINING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-015852ce9e89>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['Predicted Sentiment'] = svm.predict(test['Clean Review'])\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = sklearn.model_selection.train_test_split(training_data, train_size=0.8, test_size=0.2)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=100, \n",
    "                                           learning_rate='optimal', tol=None))])\n",
    "\n",
    "svm = pipeline.fit(train['Clean Review'], train['Sentiment'])\n",
    "test['Predicted Sentiment'] = svm.predict(test['Clean Review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GETTING THE COVID-19 VACCINE TWEETS ALONG WITH USER IDs OF PEOPLE WHO TWEETED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of covid-19 vaccine tweets extracted: 95107\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen name</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pharmanewsintel</td>\n",
       "      <td>Pfizer concludes the Phase 3 study of its #mRN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheHansIndiaWeb</td>\n",
       "      <td>Thackeray seeks 'national vaccine distribution...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>darrenculbreath</td>\n",
       "      <td>#AstraZeneca’s #COVID-19vaccine shows success:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MedicircleI</td>\n",
       "      <td>The UK’s vaccine against SARS-CoV-2 shows simi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GulfTimes_QATAR</td>\n",
       "      <td>#France is expected to loosen its #coronavirus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       screen name                                              tweet\n",
       "0  pharmanewsintel  Pfizer concludes the Phase 3 study of its #mRN...\n",
       "1  TheHansIndiaWeb  Thackeray seeks 'national vaccine distribution...\n",
       "2  darrenculbreath  #AstraZeneca’s #COVID-19vaccine shows success:...\n",
       "3      MedicircleI  The UK’s vaccine against SARS-CoV-2 shows simi...\n",
       "4  GulfTimes_QATAR  #France is expected to loosen its #coronavirus..."
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "snscrape twitter-search \"#covid-19vaccine since:2020-08-01 until:2020-11-25\" > trump_tweets1.txt\n",
    "snscrape twitter-search \"#COVID-19Vaccine since:2020-08-01 until:2020-11-25\" > trump_tweets2.txt\n",
    "snscrape twitter-search \"#covidvaccine since:2020-08-01 until:2020-11-25\" > trump_tweets3.txt\n",
    "snscrape twitter-search \"#coronavirusvaccine since:2020-08-01 until:2020-11-25\" > trump_tweets4.txt\n",
    "snscrape twitter-search \"#coronavaccine since:2020-08-01 until:2020-11-25\" > trump_tweets5.txt\n",
    "'''\n",
    "\n",
    "# Converting the text files into a single pandas dataframe.\n",
    "tweet_url = pd.read_csv(r\"C:\\Users\\Raheyma Arshad\\Desktop\\INFO 5731 Term Project\\trump_tweets1.txt\", index_col= None, header = None, names = [\"links\"])\n",
    "tweet_url2 = pd.read_csv(r\"C:\\Users\\Raheyma Arshad\\Desktop\\INFO 5731 Term Project\\trump_tweets2.txt\", index_col= None, header = None, names = [\"links\"])\n",
    "tweet_url3 = pd.read_csv(r\"C:\\Users\\Raheyma Arshad\\Desktop\\INFO 5731 Term Project\\trump_tweets3.txt\", index_col= None, header = None, names = [\"links\"])\n",
    "tweet_url4 = pd.read_csv(r\"C:\\Users\\Raheyma Arshad\\Desktop\\INFO 5731 Term Project\\trump_tweets4.txt\", index_col= None, header = None, names = [\"links\"])\n",
    "tweet_url5 = pd.read_csv(r\"C:\\Users\\Raheyma Arshad\\Desktop\\INFO 5731 Term Project\\trump_tweets5.txt\", index_col= None, header = None, names = [\"links\"])\n",
    "\n",
    "tweet_url = tweet_url.append(tweet_url2, ignore_index=True)\n",
    "tweet_url = tweet_url.append(tweet_url3, ignore_index=True)\n",
    "tweet_url = tweet_url.append(tweet_url4, ignore_index=True)\n",
    "tweet_url = tweet_url.append(tweet_url5, ignore_index=True)\n",
    "\n",
    "# Splitting the URLs and getting the id of each tweet.\n",
    "tweet_url['id'] = tweet_url.apply(lambda x: x[\"links\"].split(\"/\")[-1], axis=1)\n",
    "# Saving the tweet ids in a list.\n",
    "ids = tweet_url['id'].tolist()\n",
    "\n",
    "# Defining function to get the text from each tweet.\n",
    "def tweet_text(ids):\n",
    "    tweet_status_list = api.statuses_lookup(ids, tweet_mode= \"extended\")\n",
    "    text = pd.DataFrame()\n",
    "    for status in tweet_status_list:\n",
    "            tweet_text = {\"tweet\":status.full_text, \"screen\": status.user.screen_name}\n",
    "            text = text.append(tweet_text, ignore_index = True)\n",
    "    text.to_csv(r\"C:\\Users\\Raheyma Arshad\\Desktop\\INFO 5731 Term Project\\Analysis 03 Tweets.csv\", mode=\"a\")\n",
    "    \n",
    "# We divide our tweet ids into batches and run the above function on each batch. (Running on all the tweets ids together \n",
    "# raises error)\n",
    "ids_count = len(ids)\n",
    "batches = (ids_count - 1) // 50 + 1\n",
    "\n",
    "for i in range(batches):\n",
    "        batch = ids[i*50:(i+1)*50]\n",
    "        result = tweet_text(batch)\n",
    "\n",
    "data = pd.read_csv(r\"C:\\Users\\Raheyma Arshad\\Desktop\\INFO 5731 Term Project\\Analysis 03 Tweets.csv\")\n",
    "del data['Unnamed: 0']\n",
    "data = data[data.tweet != 'tweet']\n",
    "print('Number of covid-19 vaccine tweets extracted:', len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAMOUS PERSON: DONALD TRUMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GETTING SCREEN NAMES OF DONALD TRUMP'S FOLLOWERS AND KEEPING ONLY THEIR TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Donald Trump's followers extracted: 17065\n",
      "Covid-19 Vaccine tweets from Donald Trump's followers are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen name</th>\n",
       "      <th>tweet</th>\n",
       "      <th>Trump Follower?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15028</th>\n",
       "      <td>AndrewJGord</td>\n",
       "      <td>(9/10) Trump will distribute #Covidvaccine. Cu...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17621</th>\n",
       "      <td>CrashLandingDZ</td>\n",
       "      <td>#COVID #CovidVaccine \\nMoi je dis qu’avant la ...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26485</th>\n",
       "      <td>BolexTerry</td>\n",
       "      <td>This is really impressive https://t.co/oNWf7bH...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45512</th>\n",
       "      <td>CrashLandingDZ</td>\n",
       "      <td>#Russie #CovidVaccine #SpoutnikV \\nJubilation ...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50405</th>\n",
       "      <td>Manash43991202</td>\n",
       "      <td>What are you coming to say @WHO @DrTedros?\\n\\n...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          screen name                                              tweet  \\\n",
       "15028     AndrewJGord  (9/10) Trump will distribute #Covidvaccine. Cu...   \n",
       "17621  CrashLandingDZ  #COVID #CovidVaccine \\nMoi je dis qu’avant la ...   \n",
       "26485      BolexTerry  This is really impressive https://t.co/oNWf7bH...   \n",
       "45512  CrashLandingDZ  #Russie #CovidVaccine #SpoutnikV \\nJubilation ...   \n",
       "50405  Manash43991202  What are you coming to say @WHO @DrTedros?\\n\\n...   \n",
       "\n",
       "      Trump Follower?  \n",
       "15028             Yes  \n",
       "17621             Yes  \n",
       "26485             Yes  \n",
       "45512             Yes  \n",
       "50405             Yes  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting screen names of trump's followers\n",
    "\n",
    "trump_follower_ids = []\n",
    "for page in tw.Cursor(api.followers_ids, screen_name = 'POTUS').pages():\n",
    "    trump_follower_ids.extend(page)\n",
    "\n",
    "trump_screen_names = []\n",
    "try:\n",
    "    for id in trump_follower_ids:\n",
    "        user = api.get_user(id)\n",
    "        trump_screen_names.append(user.screen_name)\n",
    "except tw.TweepError as e:\n",
    "    print(id, str(e))\n",
    "print(\"Number of Donald Trump's followers extracted:\", len(trump_screen_names))\n",
    "    \n",
    "# Keeping tweets on Donald Trump's followers\n",
    "\n",
    "def trump_follower(x):\n",
    "    if x in trump_screen_names:\n",
    "        return 'Yes'\n",
    "    else:\n",
    "        return 'No'\n",
    "\n",
    "data['Trump Follower?'] = data['screen name'].apply(lambda x: trump_follower(x))\n",
    "trump = data[data['Trump Follower?'] == 'Yes']\n",
    "print(\"Covid-19 Vaccine tweets from Donald Trump's followers are:\")\n",
    "trump.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CLEANING AND PREPROCESSING THE TEST DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump['Clean Tweet'] = trump['tweet'].apply(lambda x: re.sub('https?:\\/\\/(www\\.)?[-a-zA-Z0–9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0–9@:%_\\+.~#?&//=]*)', '', x))\n",
    "trump['Clean Tweet'] = trump['Clean Tweet'].apply(lambda x: re.sub('[-a-zA-Z0–9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0–9@:%_\\+.~#?&//=]*)', '', x))\n",
    "trump['Clean Tweet'] = trump['Clean Tweet'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "trump['Clean Tweet'] = trump['Clean Tweet'].str.replace('[^\\w\\s]','')\n",
    "trump['Clean Tweet'] = trump['Clean Tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "trump['Clean Tweet'] = trump['Clean Tweet'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### USING THE SVM MODEL TO PREDICT SENTIMENTS OF DONALD TRUMP'S FOLLOWERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-56-51492b039a8e>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  trump['Predicted Sentiment'] = svm.predict(trump['Clean Tweet'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>screen name</th>\n",
       "      <th>Predicted Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15028</th>\n",
       "      <td>(9/10) Trump will distribute #Covidvaccine. Cu...</td>\n",
       "      <td>AndrewJGord</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17621</th>\n",
       "      <td>#COVID #CovidVaccine \\nMoi je dis qu’avant la ...</td>\n",
       "      <td>CrashLandingDZ</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26485</th>\n",
       "      <td>This is really impressive https://t.co/oNWf7bH...</td>\n",
       "      <td>BolexTerry</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45512</th>\n",
       "      <td>#Russie #CovidVaccine #SpoutnikV \\nJubilation ...</td>\n",
       "      <td>CrashLandingDZ</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50405</th>\n",
       "      <td>What are you coming to say @WHO @DrTedros?\\n\\n...</td>\n",
       "      <td>Manash43991202</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75663</th>\n",
       "      <td>Coronavirus update in USA (23.11.2020)\\n#COVID...</td>\n",
       "      <td>Kimberl46105822</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet      screen name  \\\n",
       "15028  (9/10) Trump will distribute #Covidvaccine. Cu...      AndrewJGord   \n",
       "17621  #COVID #CovidVaccine \\nMoi je dis qu’avant la ...   CrashLandingDZ   \n",
       "26485  This is really impressive https://t.co/oNWf7bH...       BolexTerry   \n",
       "45512  #Russie #CovidVaccine #SpoutnikV \\nJubilation ...   CrashLandingDZ   \n",
       "50405  What are you coming to say @WHO @DrTedros?\\n\\n...   Manash43991202   \n",
       "75663  Coronavirus update in USA (23.11.2020)\\n#COVID...  Kimberl46105822   \n",
       "\n",
       "      Predicted Sentiment  \n",
       "15028            Positive  \n",
       "17621            Positive  \n",
       "26485            Positive  \n",
       "45512             Neutral  \n",
       "50405            Positive  \n",
       "75663            Negative  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWpElEQVR4nO3de5BmdX3n8ffHYUSiCMJ0VmQYx1KyW+giSi+iRDPRVfESWBEX3BjF6E7iRlEr7lZwtxCp2pSsdyGrO4UKGFdRVHY0eCGCETWADRmGm2anFAPELUZQcBTRwe/+8fwan3l4uqd7Zk739Jz3q+qpPpffOefbfWb60+f2O6kqJEn99ZDFLkCStLgMAknqOYNAknrOIJCknjMIJKnn9lrsAuZrxYoVtXr16sUuQ5KWlGuuueZHVTUxbt6SC4LVq1czNTW12GVI0pKS5AczzfPUkCT1nEEgST1nEEhSzxkEktRzBoEk9ZxBIEk913kQJFmW5B+SfGHMvL2TXJhkU5Krkqzuuh5J0rYW4ojgjcDNM8x7DfDjqnoC8F7grAWoR5I0pNMgSLISeBFw7gxNjgfOb8MXAc9Jki5rkiRtq+sni98H/Bdg3xnmHwzcClBVW5PcDRwI/Gi4UZK1wFqAVatWzXnjR/7nC+ZdsObvmne+crFLkLQTOjsiSPJi4I6qumZn11VV66pqsqomJybGdpUhSdpBXZ4aOgY4LsktwCeBZyf565E2twOHACTZC9gPuLPDmiRJIzoLgqo6rapWVtVq4GTgsqp6xUiz9cCr2vCJrY0vUZakBbTgvY8mOROYqqr1wIeBjyXZBNzFIDAkSQtoQYKgqr4GfK0Nnz40/RfAyxaiBknSeD5ZLEk9ZxBIUs8ZBJLUcwaBJPWcQSBJPWcQSFLPGQSS1HMGgST1nEEgST1nEEhSzxkEktRzBoEk9ZxBIEk9ZxBIUs8ZBJLUcwaBJPVcly+vf1iSq5Ncl+TGJG8f0+aUJJuTbGif13ZVjyRpvC7fUHYf8Oyq2pJkOfCNJF+sqitH2l1YVa/vsA5J0iw6C4L2EvotbXR5+/hieknazXR6jSDJsiQbgDuAS6vqqjHNXppkY5KLkhzSZT2SpAfrNAiq6v6qOgJYCRyV5EkjTT4PrK6qw4FLgfPHrSfJ2iRTSaY2b97cZcmS1DsLctdQVf0EuBw4dmT6nVV1Xxs9FzhyhuXXVdVkVU1OTEx0Wqsk9U2Xdw1NJNm/De8DPBf4zkibg4ZGjwNu7qoeSdJ4Xd41dBBwfpJlDALnU1X1hSRnAlNVtR44NclxwFbgLuCUDuuRJI3R5V1DG4GnjJl++tDwacBpXdUgSdo+nyyWpJ4zCCSp5wwCSeo5g0CSes4gkKSeMwgkqecMAknqOYNAknrOIJCknjMIJKnnDAJJ6jmDQJJ6ziCQpJ4zCCSp5wwCSeo5g0CSes4gkKSe6/KdxQ9LcnWS65LcmOTtY9rsneTCJJuSXJVkdVf1SJLG6/KI4D7g2VX1ZOAI4NgkR4+0eQ3w46p6AvBe4KwO65EkjdFZENTAlja6vH1qpNnxwPlt+CLgOUnSVU2SpAfr9BpBkmVJNgB3AJdW1VUjTQ4GbgWoqq3A3cCBY9azNslUkqnNmzd3WbIk9U6nQVBV91fVEcBK4KgkT9rB9ayrqsmqmpyYmNilNUpS3y3IXUNV9RPgcuDYkVm3A4cAJNkL2A+4cyFqkiQNdHnX0ESS/dvwPsBzge+MNFsPvKoNnwhcVlWj1xEkSR3aq8N1HwScn2QZg8D5VFV9IcmZwFRVrQc+DHwsySbgLuDkDuuRJI3RWRBU1UbgKWOmnz40/AvgZV3VIEnaPp8slqSeMwgkqecMAknqOYNAknrOIJCknjMIJKnnDAJJ6jmDQJJ6ziCQpJ4zCCSp5wwCSeo5g0CSes4gkKSeMwgkqecMAknqOYNAknrOIJCknuvyncWHJLk8yU1JbkzyxjFt1iS5O8mG9jl93LokSd3p8p3FW4E/r6prk+wLXJPk0qq6aaTdFVX14g7rkCTNorMjgqr6YVVd24Z/CtwMHNzV9iRJO2ZBrhEkWc3gRfZXjZn99CTXJflikifOsPzaJFNJpjZv3txlqZLUO50HQZJHAJ8B3lRV94zMvhZ4bFU9GTgbuHjcOqpqXVVNVtXkxMREp/VKUt90GgRJljMIgY9X1WdH51fVPVW1pQ1fAixPsqLLmiRJ2+ryrqEAHwZurqr3zNDm0a0dSY5q9dzZVU2SpAfr8q6hY4A/Aq5PsqFNeyuwCqCqPgScCLwuyVbgXuDkqqoOa5IkjegsCKrqG0C20+Yc4JyuapAkbZ9PFktSzxkEktRzBoEk9ZxBIEk9N6cgSPLVuUyTJC09s941lORhwG8BK5I8it/cBfRI7DdIkvYI27t99E+ANwGPAa7hN0FwD972KUl7hFmDoKreD7w/yRuq6uwFqkmStIDm9EBZVZ2d5BnA6uFlquqCjuqSJC2QOQVBko8Bjwc2APe3yQUYBJK0xM21i4lJ4DD7AZKkPc9cnyO4AXh0l4VIkhbHXI8IVgA3JbkauG96YlUd10lVkqQFM9cgOKPLIiRJi2eudw39XdeFSJIWx1zvGvopg7uEAB4KLAd+VlWP7KowSdLCmOsRwb7Tw+3VkscDR3dVlCRp4cy799EauBh4/mztkhyS5PIkNyW5Mckbx7RJkg8k2ZRkY5KnzrceSdLOmeupoROGRh/C4LmCX2xnsa3An1fVtUn2Ba5JcmlV3TTU5gXAoe3zNOCD7askaYHM9a6hPxga3grcwuD00Iyq6ofAD9vwT5PczKDH0uEgOB64oD2odmWS/ZMc1JaVJC2AuV4jePXObCTJauApwFUjsw4Gbh0av61N2yYIkqwF1gKsWrVqZ0qRJI2Y64tpVib5XJI72uczSVbOcdlHAJ8B3lRV9+xIkVW1rqomq2pyYmJiR1YhSZrBXC8WfxRYz+C9BI8BPt+mzSrJcgYh8PGq+uyYJrcDhwyNr2zTJEkLZK5BMFFVH62qre1zHjDrn+btNtMPAzdX1XtmaLYeeGW7e+ho4G6vD0jSwprrxeI7k7wC+EQbfzlw53aWOQb4I+D6JBvatLcCqwCq6kPAJcALgU3Az4GduhYhSZq/uQbBHwNnA+9l8ITxt4BTZlugqr7Bb15tOVObAv5sjjVIkjow1yA4E3hVVf0YIMkBwLsYBIQkaQmb6zWCw6dDAKCq7mJwO6gkaYmbaxA8JMmjpkfaEcFcjyYkSbuxuf4yfzfw90k+3cZfBvz3bkqSJC2kuT5ZfEGSKeDZbdIJI30GSZKWqDmf3mm/+P3lL0l7mHl3Qy1J2rMYBJLUcwaBJPWcQSBJPWcQSFLPGQSS1HMGgST1nEEgST1nEEhSzxkEktRzBoEk9VxnQZDkI0nuSHLDDPPXJLk7yYb2Ob2rWiRJM+vynQLnAecAF8zS5oqqenGHNUiStqOzI4Kq+jpwV1frlyTtGot9jeDpSa5L8sUkT5ypUZK1SaaSTG3evHkh65OkPd5iBsG1wGOr6snA2cDFMzWsqnVVNVlVkxMTEwtVnyT1wqIFQVXdU1Vb2vAlwPIkKxarHknqq0ULgiSPTpI2fFSr5c7FqkeS+qqzu4aSfAJYA6xIchvwNmA5QFV9CDgReF2SrcC9wMlVVV3VI0kar7MgqKqXb2f+OQxuL5UkLaLFvmtIkrTIDAJJ6jmDQJJ6ziCQpJ4zCCSp5wwCSeo5g0CSes4gkKSeMwgkqecMAknqOYNAknrOIJCknjMIJKnnDAJJ6jmDQJJ6ziCQpJ4zCCSp5zoLgiQfSXJHkhtmmJ8kH0iyKcnGJE/tqhZJ0sy6PCI4Dzh2lvkvAA5tn7XABzusRZI0g86CoKq+Dtw1S5PjgQtq4Epg/yQHdVWPJGm8zl5ePwcHA7cOjd/Wpv1wtGGStQyOGli1atWCFKfF909n/uvFLmGPt+r06ztb9zFnH9PZujXwzTd8c5esZ0lcLK6qdVU1WVWTExMTi12OJO1RFjMIbgcOGRpf2aZJkhbQYgbBeuCV7e6ho4G7q+pBp4UkSd3q7BpBkk8Aa4AVSW4D3gYsB6iqDwGXAC8ENgE/B17dVS2SpJl1FgRV9fLtzC/gz7raviRpbpbExWJJUncMAknqOYNAknrOIJCknjMIJKnnDAJJ6jmDQJJ6ziCQpJ4zCCSp5wwCSeo5g0CSes4gkKSeMwgkqecMAknqOYNAknrOIJCknjMIJKnnOg2CJMcm+W6STUn+Ysz8U5JsTrKhfV7bZT2SpAfr8p3Fy4C/Ap4L3AZ8O8n6qrpppOmFVfX6ruqQJM2uyyOCo4BNVfW9qvol8Eng+A63J0naAV0GwcHArUPjt7Vpo16aZGOSi5IcMm5FSdYmmUoytXnz5i5qlaTeWuyLxZ8HVlfV4cClwPnjGlXVuqqarKrJiYmJBS1QkvZ0XQbB7cDwX/gr27QHVNWdVXVfGz0XOLLDeiRJY3QZBN8GDk3yuCQPBU4G1g83SHLQ0OhxwM0d1iNJGqOzu4aqamuS1wNfBpYBH6mqG5OcCUxV1Xrg1CTHAVuBu4BTuqpHkjReZ0EAUFWXAJeMTDt9aPg04LQua5AkzW6xLxZLkhaZQSBJPWcQSFLPGQSS1HMGgST1nEEgST1nEEhSzxkEktRzBoEk9ZxBIEk9ZxBIUs8ZBJLUcwaBJPWcQSBJPWcQSFLPGQSS1HMGgST1XKdBkOTYJN9NsinJX4yZv3eSC9v8q5Ks7rIeSdKDdRYESZYBfwW8ADgMeHmSw0aavQb4cVU9AXgvcFZX9UiSxuvyiOAoYFNVfa+qfgl8Ejh+pM3xwPlt+CLgOUnSYU2SpBFdvrz+YODWofHbgKfN1Kaqtia5GzgQ+NFwoyRrgbVtdEuS73ZS8e5hBSPf/+4u73rVYpewO1la++9t/t01ZGntOyCnzmv/PXamGV0GwS5TVeuAdYtdx0JIMlVVk4tdh3aM+2/p6vO+6/LU0O3AIUPjK9u0sW2S7AXsB9zZYU2SpBFdBsG3gUOTPC7JQ4GTgfUjbdYD0+cVTgQuq6rqsCZJ0ojOTg21c/6vB74MLAM+UlU3JjkTmKqq9cCHgY8l2QTcxSAs+q4Xp8D2YO6/pau3+y7+AS5J/eaTxZLUcwaBJPWcQbCLJLk/yYYkNyT5dJLfmufyj0lyURs+IskLh+YdN66LDu06SSrJu4fG35LkjB1c1/5J/tMOLntLkhU7smyf7Mr9tZ3tvHVk/Fu7ehu7A4Ng17m3qo6oqicBvwT+dD4LV9U/V9WJbfQI4IVD89ZX1Tt2WaUa5z7ghF30S3h/YGwQtNuktfN25f6azTZBUFXP6Hh7i8Ig6MYVwBOSHJDk4iQbk1yZ5HCAJL/Xjh42JPmHJPsmWd2OJh4KnAmc1OaflOSUJOck2S/JD5I8pK3n4UluTbI8yeOTfCnJNUmuSPKvFvH7X4q2Mrhr5M2jM5JMJPlMkm+3zzFt+hlJ3jLU7obWceI7gMe3/ffOJGvaPlkP3NTaXtz21Y3tyXnNz47sr4kkl7af+bnt/9KKNu9B+yPJO4B92n78eJu2pX39ZJIXDW3zvCQnJlnW9vm32//7P+n8J7ErVJWfXfABtrSvewH/B3gdcDbwtjb92cCGNvx54Jg2/Ii2zGrghjbtFOCcoXU/MN7W/ftt+CTg3Db8VeDQNvw0Bs9kLPrPZal8gC3AI4FbGDzY+BbgjDbvfwO/24ZXATe34TOAtwyt44a2Hx/Yl236GuBnwOOGph3Qvu7Tljuwjd8CrFjsn8fu/tnB/XUOcFobPhao6Z/1LPtjy+h229eXAOe34Ycy6CpnHwZd4fy3Nn1vYGp4v++uHw9Td519kmxow1cweEbiKuClAFV1WZIDkzwS+CbwnvZXxmer6rZ59LV3IYMAuJzBcxf/M8kjgGcAnx5az947/y31S1Xdk+QC4FTg3qFZ/xY4bOhn+8j2M5+Pq6vq+0PjpyZ5SRs+BDgUn6qflx3YX7/L4Bc4VfWlJD8eWma+++OLwPuT7M0gVL5eVfcmeR5weJLp07z7tXV9f4b17BYMgl3n3qo6YnjCTL/cq+odSf6GwXWAbyZ5PvCLOW5nPfCXSQ4AjgQuAx4O/GR0+9oh7wOuBT46NO0hwNFVtc0+SrKVbU+vPmyW9f5saLk1DH5ZPb2qfp7ka9tZVjN7H3PfX2NXsCP7o6p+0do9n8EfZp+cXh3whqr68vy+jcXlNYJuXQH8ITzwj+1H7a+Yx1fV9VV1FoOuOEbP5/8U2HfcCqtqS1vm/cAXqur+qroH+H6Sl7VtJcmTu/iG9nRVdRfwKQbvypj2FeAN0yNJjmiDtwBPbdOeCjyuTZ9x/zX7MXgPx8/btZyjd0XtfTTP/fVN4N+3ac8DHtWmz7Y/fpVk+QybvxB4NfBM4Ett2peB100vk+R3kjx8x767hWMQdOsM4MgkGxlcQJzuV+lN7cLiRuBXDA4zh13O4NB2Q5KTxqz3QuAV7eu0PwRek+Q64EYe/O4Hzd27GXRJPO1UYLJd/LuJ39wR9hnggCQ3Aq8H/hGgqu5kcKR3Q5J3jln/l4C9ktzM4N/FlR19H30x1/31duB5SW4AXgb8PwahPdv+WAdsnL5YPOIrwO8Bf1uDd64AnMvghoBr23b+F0vgzItdTEjqhXY+//4a9IP2dOCDnk4d2O2TSpJ2kVXAp9rt178E/uMi17Pb8IhAknrOawSS1HMGgST1nEEgST1nEGi3kJ3svXVkXedNP9nZ+pQ5bJa2a5LMuyOxzNBLaJI/TnJ9u3XxhiQ7dBtvBn1P/Yeh8ckkH9iRdc1jm9v0eqv+MAi0u5i199bsYK+dVfXaqrppliZrGHTPsdOSrAT+K4N+bg5n8GDSxh1c3WrggSCoqqmqOnWni5zdEQz1eqv+MAi0O5ruvXWbXjtn6tmxPUl9TpLvJvlb4LenV5Tka0km2/CxSa5Ncl2Sr2bQU+ifAm9uRyPPzMw9Vx6Y5CtpPVcy6Epg1G8zeEBpCwyeAp/uXygz9A7bjl4+kORbSb431EfNO4Bntrre3H4WX2jLnJHk/LaeHyQ5Icn/aEciXxp6qvXIJH/XtvnlJAcN/UzOSnJ1kn9s3/eDer3dVTtTS8Bi93rnx0/VjL23rmGo105m6NkROAG4FFgGPAb4CXBia/c1YBKYYNBD5PS6pnubPINtexCdqefKDwCnt+EXMdRz5dCyyxh0MfBPDPq++YOheWN7hwXOAz7N4I+yw4BNbfoaBl2IMDreav4GsBx4MvBz4AVt3ueAf9fmfQuYaNNPAj4y9DN5dxt+IYMnY2Gk11s//fn4QJl2F+N6b30G2/baOVPPjs8CPlFV9wP/nOSyMes/mkEPkd+HB/qoGWemniufxSBwqKq/ybY9V9Km35/kWODfAM8B3pvkSOBdzN477MVV9WsGRz3/Yoa6Rn2xqn6V5HoGATTd1831DE4r/UvgScClbZvLgB8OLf/Z9vWa1l49ZhBodzFT760/G57EmJ4dd/EFznn1XDmqqgq4Grg6yaUMjgzew+y9w943vKk51nlf296vk/yqbRfg1wz+Xwe4saqevp1t3o+/B3rPawRaSmbq2fHrDM5tL2vnwX9/zLJXAs9K8ri27AFt+mhPoTP1XPl12sXbJC/gNz1XMtT2MRn0QjrtCOAHtWO9w26vB9Pt+S4wkUGfOmTwFrsndrxNLVEGgZaSmXp2/Bzwf9u8C4C/H12wqjYzuMbw2Qx6aJ3uufXzwEumLxYze8+Vz8qgp9ETGFwHGLUceFeS77TTXCcBb2zz5ts77Ebg/nZh+0GvY9yeGvSGeSJwVtvmBrZ/d9T2er3VHsq+hiSp5zwikKSeMwgkqecMAknqOYNAknrOIJCknjMIJKnnDAJJ6rn/D5LKee4XREwcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trump['Predicted Sentiment'] = svm.predict(trump['Clean Tweet'])\n",
    "\n",
    "# Plotting the distribution of sentiments in the covid-19 vaccine tweets dataset\n",
    "import seaborn as sns\n",
    "sns.countplot(trump['Predicted Sentiment'])\n",
    "\n",
    "trump[['tweet', 'screen name', 'Predicted Sentiment']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
